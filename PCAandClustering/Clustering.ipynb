{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"EJZ_K7vCX37p"}},{"cell_type":"markdown","source":["#Clustering Task for the Dataset"],"metadata":{"id":"zhvzt6EMX4rE"}},{"cell_type":"markdown","source":["#### CSV files are obtained from the directory, necessary imports are done.\n","\n","---\n","\n","\n","\n"],"metadata":{"id":"FRcHzTqtYA8w"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import random\n","\n","import copy\n","import matplotlib.pyplot as plt\n","import time\n","drive.mount('/content/drive')\n","MY_DRIVE_PATH = \"/content/drive/MyDrive/MLProject_2\"\n","DATA_FOLDER = os.path.join(MY_DRIVE_PATH, 'Data google sheet')\n","PROCESSED_CSV_FILE = os.path.join(DATA_FOLDER, 'Processed_Fruits_Data.csv')\n","ONEHOT_CSV_FILE = os.path.join(DATA_FOLDER, 'One_Hot_Processed_Fruits_Data.csv')\n","PCA_CSV_PATH = os.path.join(DATA_FOLDER, 'PCA_Processed_Fruits.csv')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxTNWq_cNkSF","executionInfo":{"status":"ok","timestamp":1767681735278,"user_tz":-180,"elapsed":18114,"user":{"displayName":"Cengiz Sarı","userId":"07073946851309561314"}},"outputId":"f72a722b-7722-4fb5-f9b4-1b4336fab2f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#### Prepare dataset for clustering\n","\n"],"metadata":{"id":"6TrB0yq8YZ8Z"}},{"cell_type":"code","source":["df = pd.read_csv(ONEHOT_CSV_FILE, sep = \";\")\n","np.random.seed(42)\n","# Clean up columns (Remove non-numeric metadata)\n","df.drop(columns=[\"Image_path\", \"Text\", \"Label\"], inplace=True)\n","\n","# Identify columns for normalization\n","numerical_cols = [\"Weight\", \"Price\"]\n","image_cols = [col for col in df.columns if \"img\" in col]\n","text_cols = [col for col in df.columns if \"text\" in col]\n","\n","# Normalizing every image histogram\n","for idx in range(len(df)):\n","    hist_values = df.loc[idx, image_cols].values.astype(np.float64)\n","    total = hist_values.sum()\n","    if total > 0:\n","        df.loc[idx, image_cols] = hist_values / total\n","    else:\n","        df.loc[idx, image_cols] = 0\n","\n","# Combined list of all feature columns (excluding the 'Fruit' target)\n","columns_to_normalize = numerical_cols + image_cols + text_cols\n","\n","# Apply Normalization to the whole DataFrame\n","epsilon = 1e-8\n","for column in columns_to_normalize:\n","    mean = df[column].mean()\n","    std = df[column].std()\n","    df[column] = (df[column] - mean) / (std + epsilon)\n","\n","# Prepare data for Clustering\n","# We drop 'Fruit' because K-means shouldn't see the answer\n","X_clustering_raw = df.drop(columns=['Fruit']).to_numpy()\n","\n","# We keep the labels separately for the External Metric (Rand Index) later\n","y_true_labels = df['Fruit'].values\n","\n","print(f\"Data ready for clustering without PCA. Shape: {X_clustering_raw.shape}\")"],"metadata":{"id":"Ui5LQmzWOJWP","executionInfo":{"status":"ok","timestamp":1767681785857,"user_tz":-180,"elapsed":47904,"user":{"displayName":"Cengiz Sarı","userId":"07073946851309561314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"27d0ff21-2934-4bb1-8472-5b51a92d083c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data ready for clustering without PCA. Shape: (3182, 492)\n"]}]},{"cell_type":"markdown","source":["#### Clustering Algorithm\n","We used the K-means++ algorithm for clustering. First, we tried generic k-means, but we experienced the effect of the initial centroids problem, so we decided to add a probabilistic selection of initial centroids part before the generic k-means algorithm part."],"metadata":{"id":"-C-acdkcZPNN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pxsr394UMGe4"},"outputs":[],"source":["def kmeans_scratch_plusplus(X, k, max_iters=100, tol=1e-4):\n","    np.random.seed(42)\n","    n_samples, n_features = X.shape\n","\n","\n","    #first centroid\n","    centroids = [X[np.random.randint(n_samples)]]\n","\n","    for _ in range(1, k):\n","        # distances from all points to the nearest existing centroid\n","        dist_sq = np.array([min([np.linalg.norm(x - c)**2 for c in centroids]) for x in X])\n","\n","        #probabilities\n","        probs = dist_sq / dist_sq.sum()\n","        cumulative_probs = np.cumsum(probs)\n","        #next centroid\n","        r = np.random.rand()\n","        for j, p in enumerate(cumulative_probs):\n","            if r < p:\n","                centroids.append(X[j])\n","                break\n","    centroids = np.array(centroids)\n","    #K-Means Loop\n","    for i in range(max_iters):\n","        # assignment\n","        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n","        labels = np.argmin(distances, axis=1)\n","\n","        #update\n","        new_centroids = np.array([X[labels == j].mean(axis=0) if len(X[labels == j]) > 0\n","                                  else centroids[j] for j in range(k)])\n","\n","        if np.all(np.abs(new_centroids - centroids) < tol):\n","            break\n","        centroids = new_centroids\n","\n","    return centroids, labels"]},{"cell_type":"markdown","source":["Since we know that there should be 5 clusters since we have 5 class, we directly give 5 to k."],"metadata":{"id":"mOOU_388ZoqM"}},{"cell_type":"code","source":["X_clustering = df.drop(columns=['Fruit']).to_numpy()\n","\n","k = 5\n","centroids, labels = kmeans_scratch_plusplus(X_clustering, k)\n","print(\"Clustering is ended. Assigned\", len(labels), \"points to\",k ,\"clusters.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfwlcEyPOXQb","executionInfo":{"status":"ok","timestamp":1767681812522,"user_tz":-180,"elapsed":854,"user":{"displayName":"Cengiz Sarı","userId":"07073946851309561314"}},"outputId":"39392abb-5e1f-46b9-f374-40056e910a6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Clustering is ended. Assigned 3182 points to 5 clusters.\n"]}]},{"cell_type":"markdown","source":["#### Internal Metric: ***Silhouette Score***\n","Reference: ***https://www.geeksforgeeks.org/machine-learning/what-is-silhouette-score/***\n","\n","We searched for internal metrics, and the first one we saw was the ***silhouette score***, which is intuitive and easy to understand.\n","With this score, we mainly try to minimize:\n","\n","***Intra-cluster distance***: The average distance between point $i$ and all other points in the same cluster.\n","\n","and try to maximize:\n","\n","***Nearest-cluster distance***: The average distance between point $i$ and all points in the nearest neighboring cluster.\n","\n","The metric gives the difference of these two; having bigger number as a metric is a good indication for the dataset."],"metadata":{"id":"vNoVRVOIZxoK"}},{"cell_type":"code","source":["# For intrinsic metric, we will measure how similar an object is to its own cluste compared to other clusters\n","# This is called as Silhouette score in the literature.\n","def silhouette(X, labels):\n","    n_samples = X.shape[0]\n","    unique_labels = np.unique(labels)\n","\n","    #pairwise  Euclidean distance matrix\n","    dist_matrix = np.sqrt(((X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2).sum(axis=2))\n","\n","    silhouettes = []\n","    for i in range(n_samples):\n","        curr_label = labels[i]\n","\n","        # Average distance to other points in the same cluster\n","        same_cluster_idx = np.where(labels == curr_label)[0]\n","        avg_dist_same_cluster_i = np.mean(dist_matrix[i, same_cluster_idx[same_cluster_idx != i]])\n","\n","        #Average distance to points in the closest other cluster\n","        avg_dist_other_clusters_i = np.inf\n","        for other_label in unique_labels:\n","            if other_label == curr_label:\n","                continue\n","            other_cluster_idx = np.where(labels == other_label)[0]\n","            avg_dist_other = np.mean(dist_matrix[i, other_cluster_idx])\n","            avg_dist_other_clusters_i = min(avg_dist_other_clusters_i, avg_dist_other)\n","\n","        # Silhouette for this specific point\n","        s_i = (avg_dist_other_clusters_i - avg_dist_same_cluster_i) / max(avg_dist_same_cluster_i, avg_dist_other_clusters_i) if max(avg_dist_same_cluster_i, avg_dist_other_clusters_i) > 0 else 0\n","        silhouettes.append(s_i)\n","\n","    return np.mean(silhouettes)"],"metadata":{"id":"GKxXEAd7Oiuh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#take part of the sample  for the RAM issues.\n","sample_size = min(1000, X_clustering.shape[0])\n","idx = np.random.choice(X_clustering.shape[0], sample_size, replace=False)\n","\n","internal_score = silhouette(X_clustering[idx], labels[idx])\n","\n","print(k, \"Clusters\")\n","print(\"Silhouette Score: \" ,internal_score)\n"],"metadata":{"id":"3ompi6nsnEzH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767681818271,"user_tz":-180,"elapsed":3260,"user":{"displayName":"Cengiz Sarı","userId":"07073946851309561314"}},"outputId":"fac30d6b-9fcf-4bcb-bb20-804771e52c7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5 Clusters\n","Silhouette Score:  0.12992554588312472\n"]}]},{"cell_type":"markdown","source":["### Evaluation of the Internal Metric\n","The references suggest that bigger than 0.5 ***silhoutte score*** suggests good structure for clustering. We have a really low number for this metric , the most probable reason is that our image features prevent the good structure for clustering, the background of the images could be extracted for better clustering, or may be the HSV values are not enough."],"metadata":{"id":"9baLv2mYbOeA"}},{"cell_type":"markdown","source":["#### External Metric: ***Adjusted Rand Index***\n","Reference: ***https://www.sciencedirect.com/topics/computer-science/adjusted-rand-index***\n","\n","***https://medium.com/@samson.sabu/rand-index-ri-vs-adjusted-rand-index-ari-in-k-means-clustering-06c364bdf1ef***\n","\n","We searched for external metrics; it was hard to understand these metrics compared to the internal ones. AI suggests us the rand index and adjusted rand index. We decided to use the adjusted rand index since it is the improved version of the rand index and considers the effect of accurate clustering randomly by chance.\n","\n","\n","\n","$$ARI = \\frac{\\text{Index} - \\text{Expected Index}}{\\text{Max Index} - \\text{Expected Index}}$$\n","\n","\n","\n","The Adjusted part subtracts the Expected Index (what score we would get if we assigned clusters randomly) from the actual result.\n","\n","\n","\n","\n","\n","**Confusion Matrix** rows represent the actual fruit types, columns represent the cluster indices.\n","\n","The metric checks the pairwise probability of having the same cluster index and the same fruit type at the same time."],"metadata":{"id":"3Dllk-Shbx81"}},{"cell_type":"code","source":["def adjusted_rand_index_numpy(y_true, y_pred):\n","    #Classes and Clusters\n","    classes, class_idx = np.unique(y_true, return_inverse=True)\n","    clusters, cluster_idx = np.unique(y_pred, return_inverse=True)\n","    n = len(y_true)\n","\n","    #Contingency Table\n","    contingency = np.zeros((len(classes), len(clusters)))\n","    for i in range(n):\n","        contingency[class_idx[i], cluster_idx[i]] += 1\n","\n","    #Continency Table ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"CONTINGENCY TABLE (Rows: True Label | Cols: Cluster ID)\")\n","    print(\"=\"*60)\n","\n","    # Header: C0, C1, C2, C3, C4\n","    header = \"True Label\".ljust(15) + \"\".join([f\"C{c}\".rjust(8) for c in range(len(clusters))])\n","    print(header)\n","    print(\"-\" * len(header))\n","\n","    for i, fruit_name in enumerate(classes):\n","        counts = contingency[i]\n","        row_str = \"\".join([f\"{int(c)}\".rjust(8) for c in counts])\n","        print(f\"{fruit_name.ljust(15)}{row_str}\")\n","\n","    print(\"=\"*60 + \"\\n\")\n","\n","    #ARI Calculation\n","    # It calculates the all pairs for clusters and classes with comb_col and comb_row\n","    # With comb_c, it calculates the aggreements of the cluster and class count\n","    sum_comb_c = np.sum([n_ij * (n_ij - 1) / 2 for n_ij in contingency.flatten()])\n","    sum_comb_row = np.sum([ni * (ni - 1) / 2 for ni in contingency.sum(axis=1)])\n","    sum_comb_col = np.sum([nj * (nj - 1) / 2 for nj in contingency.sum(axis=0)])\n","\n","    total_comb = n * (n - 1) / 2\n","    expected_index = (sum_comb_row * sum_comb_col) / total_comb\n","    max_index = (sum_comb_row + sum_comb_col) / 2\n","\n","    return (sum_comb_c - expected_index) / (max_index - expected_index)\n","\n","external_score = adjusted_rand_index_numpy(df['Fruit'].values, labels)\n","print(f\"External Metric (Adjusted Rand Index): {external_score:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9ThLTVgRHuk","executionInfo":{"status":"ok","timestamp":1767681818320,"user_tz":-180,"elapsed":14,"user":{"displayName":"Cengiz Sarı","userId":"07073946851309561314"}},"outputId":"e5cd2c5e-7c30-4916-81b5-67f80c901585"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","CONTINGENCY TABLE (Rows: True Label | Cols: Cluster ID)\n","============================================================\n","True Label           C0      C1      C2      C3      C4\n","-------------------------------------------------------\n","apple               118     250     191       0      63\n","banana              135     219     195      44      63\n","orange              113     191     180      66      58\n","tangerine           130     211     221      45      61\n","tomato              130     188     203      45      62\n","============================================================\n","\n","External Metric (Adjusted Rand Index): 0.0020\n"]}]},{"cell_type":"markdown","source":["### Evaluation of the External Metric\n","The results indicate that our clustering  has failed to find any meaningful patterns related to the fruit types. An Adjusted Rand Index (ARI) of 0.0020 is nearly zero, meaning that the clustering fails, and the reasons are similar to internal metrics."],"metadata":{"id":"TgzS2-NzdyHA"}},{"cell_type":"markdown","source":["#### Outlier Detection Method\n","For every individual data point, the code calculates the Euclidean distance ($L_2$ norm) between that point and the center (centroid) of the cluster it was assigned to.\n"," Threshold Mechanism: We uses a percentile-based threshold. By setting threshold_percentile=95,we define an outlier as any point whose distance to its centroid is in the top 5% of all distances in the dataset."],"metadata":{"id":"6wv4q62gebtz"}},{"cell_type":"code","source":["def detect_outliers_by_cluster(X, centroids, labels, threshold_percentile=95):\n","    #Outliers are the  points that are furthest from their assigned centroids.\n","    distances = []\n","\n","    for i in range(len(X)):\n","        centroid = centroids[labels[i]]\n","        dist = np.linalg.norm(X[i] - centroid)\n","        distances.append(dist)\n","\n","    distances = np.array(distances)\n","\n","    #distance threshold for the top X% furthest points\n","    threshold = np.percentile(distances, threshold_percentile)\n","\n","    outlier_booleans = distances > threshold\n","\n","    return outlier_booleans, distances\n","\n","outlier_booleans, dists = detect_outliers_by_cluster(X_clustering, centroids, labels)\n","\n","# the indices of the top outliers\n","outlier_indices = np.where(outlier_booleans)[0]\n","print(f\"Total Outliers detected: {len(outlier_indices)}\")\n","print(outlier_indices)"],"metadata":{"id":"c1Lb92qqRRyO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767681818702,"user_tz":-180,"elapsed":10,"user":{"displayName":"Cengiz Sarı","userId":"07073946851309561314"}},"outputId":"3fdd16fb-5110-4bca-fe91-d2d224bd33fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Outliers detected: 160\n","[   9   31   51   64   76   82   89  103  193  224  232  240  304  322\n","  339  390  420  436  502  514  516  551  598  615  616  621  634  653\n","  665  675  710  712  796  806  811  818  851  870  885  900  909  916\n","  931  937  943  963  988 1002 1013 1032 1048 1073 1079 1132 1137 1148\n"," 1160 1200 1213 1236 1242 1254 1286 1287 1293 1305 1307 1311 1313 1358\n"," 1386 1394 1435 1483 1517 1529 1531 1539 1560 1595 1607 1621 1623 1634\n"," 1697 1705 1712 1720 1740 1767 1770 1798 1820 1825 1836 1850 1872 1879\n"," 1893 1894 1898 1902 1912 1935 1940 1955 1957 1963 1964 2046 2080 2145\n"," 2160 2213 2214 2224 2245 2246 2254 2280 2286 2293 2322 2339 2359 2377\n"," 2379 2394 2412 2445 2471 2501 2543 2554 2603 2607 2616 2628 2680 2694\n"," 2731 2778 2822 2836 2847 2852 2887 2923 2928 2934 2974 2992 3011 3052\n"," 3075 3076 3104 3107 3120 3179]\n"]}]}]}