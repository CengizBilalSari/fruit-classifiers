{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Clustering Task for the Dataset with PCA"],"metadata":{"id":"TqyZy-ychGSW"}},{"cell_type":"markdown","source":["#### CSV files are obtained from the directory, necessary imports are done.\n"],"metadata":{"id":"EPEvH2bghfLO"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import random\n","import copy\n","import matplotlib.pyplot as plt\n","import time\n","drive.mount('/content/drive')\n","MY_DRIVE_PATH = \"/content/drive/MyDrive/MLProject_2\"\n","DATA_FOLDER = os.path.join(MY_DRIVE_PATH, 'Data google sheet')\n","PROCESSED_CSV_FILE = os.path.join(DATA_FOLDER, 'Processed_Fruits_Data.csv')\n","ONEHOT_CSV_FILE = os.path.join(DATA_FOLDER, 'One_Hot_Processed_Fruits_Data.csv')\n","PCA_CSV_PATH = os.path.join(DATA_FOLDER, 'PCA_Processed_Fruits.csv')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxTNWq_cNkSF","executionInfo":{"status":"ok","timestamp":1767518040121,"user_tz":-180,"elapsed":18365,"user":{"displayName":"Efe Feyzi Mantaroğlu","userId":"06606282886702319342"}},"outputId":"163311d6-e77e-4b15-ea97-11bb928867d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["df = pd.read_csv(PCA_CSV_PATH, sep = \",\")\n","np.random.seed(42)\n"],"metadata":{"id":"Ui5LQmzWOJWP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Clustering Algorithm\n","We used the K-means++ algorithm for clustering. First, we tried generic k-means, but we experienced the effect of the initial centroids problem, so we decided to add a probabilistic selection of initial centroids part before the generic k-means algorithm part."],"metadata":{"id":"OUgZPBx1hn8M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pxsr394UMGe4"},"outputs":[],"source":["def kmeans_scratch_plusplus(X, k, max_iters=100, tol=1e-4):\n","    np.random.seed(42)\n","    n_samples, n_features = X.shape\n","\n","\n","    #first centroid\n","    centroids = [X[np.random.randint(n_samples)]]\n","\n","    for _ in range(1, k):\n","        # distances from all points to the nearest existing centroid\n","        dist_sq = np.array([min([np.linalg.norm(x - c)**2 for c in centroids]) for x in X])\n","\n","        #probabilities\n","        probs = dist_sq / dist_sq.sum()\n","        cumulative_probs = np.cumsum(probs)\n","        #next centroid\n","        r = np.random.rand()\n","        for j, p in enumerate(cumulative_probs):\n","            if r < p:\n","                centroids.append(X[j])\n","                break\n","    centroids = np.array(centroids)\n","    #K-Means Loop\n","    for i in range(max_iters):\n","        # assignment\n","        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n","        labels = np.argmin(distances, axis=1)\n","\n","        #update\n","        new_centroids = np.array([X[labels == j].mean(axis=0) if len(X[labels == j]) > 0\n","                                  else centroids[j] for j in range(k)])\n","\n","        if np.all(np.abs(new_centroids - centroids) < tol):\n","            break\n","        centroids = new_centroids\n","\n","    return centroids, labels"]},{"cell_type":"markdown","source":["Since we know that there should be 5 clusters since we have 5 class, we directly give 5 to k."],"metadata":{"id":"d_56QSwlhvhJ"}},{"cell_type":"code","source":["X_clustering = df.drop(columns=['Fruit']).to_numpy()\n","\n","k = 5\n","centroids, labels = kmeans_scratch_plusplus(X_clustering, k)\n","print(\"Clustering is ended. Assigned\", len(labels), \"points to\",k ,\"clusters.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfwlcEyPOXQb","executionInfo":{"status":"ok","timestamp":1767518042033,"user_tz":-180,"elapsed":258,"user":{"displayName":"Efe Feyzi Mantaroğlu","userId":"06606282886702319342"}},"outputId":"47aa236b-eb80-4eca-a735-cf0f861772b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Clustering is ended. Assigned 3182 points to 5 clusters.\n"]}]},{"cell_type":"markdown","source":["#### Internal Metric: ***Silhouette Score***\n","Reference: ***https://www.geeksforgeeks.org/machine-learning/what-is-silhouette-score/***\n","\n","We searched for internal metrics, and the first one we saw was the ***silhouette score***, which is intuitive and easy to understand.\n","With this score, we mainly try to minimize:\n","\n","***Intra-cluster distance***: The average distance between point $i$ and all other points in the same cluster.\n","\n","and try to maximize:\n","\n","***Nearest-cluster distance***: The average distance between point $i$ and all points in the nearest neighboring cluster.\n","\n","The metric gives the difference of these two; having bigger number as a metric is a good indication for the dataset."],"metadata":{"id":"47r0vu3Dhx8C"}},{"cell_type":"code","source":["# For intrinsic metric, we will measure how similar an object is to its own cluste compared to other clusters\n","# This is called as Silhouette score in the literature.\n","def silhouette(X, labels):\n","    n_samples = X.shape[0]\n","    unique_labels = np.unique(labels)\n","\n","    #pairwise  Euclidean distance matrix\n","    dist_matrix = np.sqrt(((X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2).sum(axis=2))\n","\n","    silhouettes = []\n","    for i in range(n_samples):\n","        curr_label = labels[i]\n","\n","        # Average distance to other points in the same cluster\n","        same_cluster_idx = np.where(labels == curr_label)[0]\n","        avg_dist_same_cluster_i = np.mean(dist_matrix[i, same_cluster_idx[same_cluster_idx != i]])\n","\n","        #Average distance to points in the closest other cluster\n","        avg_dist_other_clusters_i = np.inf\n","        for other_label in unique_labels:\n","            if other_label == curr_label:\n","                continue\n","            other_cluster_idx = np.where(labels == other_label)[0]\n","            avg_dist_other = np.mean(dist_matrix[i, other_cluster_idx])\n","            avg_dist_other_clusters_i = min(avg_dist_other_clusters_i, avg_dist_other)\n","\n","        # Silhouette for this specific point\n","        s_i = (avg_dist_other_clusters_i - avg_dist_same_cluster_i) / max(avg_dist_same_cluster_i, avg_dist_other_clusters_i) if max(avg_dist_same_cluster_i, avg_dist_other_clusters_i) > 0 else 0\n","        silhouettes.append(s_i)\n","\n","    return np.mean(silhouettes)"],"metadata":{"id":"GKxXEAd7Oiuh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_size = min(5000, X_clustering.shape[0])\n","idx = np.random.choice(X_clustering.shape[0], sample_size, replace=False)\n","\n","internal_score = silhouette(X_clustering[idx], labels[idx])\n","\n","print(k, \"Clusters\")\n","print(\"Silhouette Score: \" ,internal_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9ThLTVgRHuk","executionInfo":{"status":"ok","timestamp":1767518045530,"user_tz":-180,"elapsed":3465,"user":{"displayName":"Efe Feyzi Mantaroğlu","userId":"06606282886702319342"}},"outputId":"b11ae055-53bc-4c92-a07a-9779c9b2e96f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5 Clusters\n","Silhouette Score:  0.21678286995938365\n"]}]},{"cell_type":"markdown","source":["### Evaluation of the Internal Metric\n","The references suggest that bigger than 0.5 ***silhoutte score*** suggests good structure for clustering. We have a really low number for this metric , the most probable reason is that our image features prevent the good structure for clustering, the background of the images could be extracted for better clustering, or may be the HSV values are not enough.\n","There is a slight increase compare to original dataset, the PCA improves the internal metric."],"metadata":{"id":"8TXCYEszh2_1"}},{"cell_type":"markdown","source":["#### External Metric: ***Adjusted Rand Index***\n","Reference: ***https://www.sciencedirect.com/topics/computer-science/adjusted-rand-index***\n","\n","***https://medium.com/@samson.sabu/rand-index-ri-vs-adjusted-rand-index-ari-in-k-means-clustering-06c364bdf1ef***\n","\n","We searched for external metrics; it was hard to understand these metrics compared to the internal ones. AI suggests us the rand index and adjusted rand index. We decided to use the adjusted rand index since it is the improved version of the rand index and considers the effect of accurate clustering randomly by chance.\n","\n","\n","\n","$$ARI = \\frac{\\text{Index} - \\text{Expected Index}}{\\text{Max Index} - \\text{Expected Index}}$$\n","\n","\n","\n","The Adjusted part subtracts the Expected Index (what score we would get if we assigned clusters randomly) from the actual result.\n","\n","\n","\n","\n","\n","**Confusion Matrix** rows represent the actual fruit types, columns represent the cluster indices.\n","\n","The metric checks the pairwise probability of having the same cluster index and the same fruit type at the same time."],"metadata":{"id":"Az8FOrhFiKgj"}},{"cell_type":"code","source":["def adjusted_rand_index_numpy(y_true, y_pred):\n","    #Classes and Clusters\n","    classes, class_idx = np.unique(y_true, return_inverse=True)\n","    clusters, cluster_idx = np.unique(y_pred, return_inverse=True)\n","    n = len(y_true)\n","\n","    #Contingency Table\n","    contingency = np.zeros((len(classes), len(clusters)))\n","    for i in range(n):\n","        contingency[class_idx[i], cluster_idx[i]] += 1\n","\n","    #Continency Table ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"CONTINGENCY TABLE (Rows: True Label | Cols: Cluster ID)\")\n","    print(\"=\"*60)\n","\n","    # Header: C0, C1, C2, C3, C4\n","    header = \"True Label\".ljust(15) + \"\".join([f\"C{c}\".rjust(8) for c in range(len(clusters))])\n","    print(header)\n","    print(\"-\" * len(header))\n","\n","    for i, fruit_name in enumerate(classes):\n","        counts = contingency[i]\n","        row_str = \"\".join([f\"{int(c)}\".rjust(8) for c in counts])\n","        print(f\"{fruit_name.ljust(15)}{row_str}\")\n","\n","    print(\"=\"*60 + \"\\n\")\n","\n","    #ARI Calculation\n","    # It calculates the all pairs for clusters and classes with comb_col and comb_row\n","    # With comb_c, it calculates the aggreements of the cluster and class count\n","    sum_comb_c = np.sum([n_ij * (n_ij - 1) / 2 for n_ij in contingency.flatten()])\n","    sum_comb_row = np.sum([ni * (ni - 1) / 2 for ni in contingency.sum(axis=1)])\n","    sum_comb_col = np.sum([nj * (nj - 1) / 2 for nj in contingency.sum(axis=0)])\n","\n","    total_comb = n * (n - 1) / 2\n","    expected_index = (sum_comb_row * sum_comb_col) / total_comb\n","    max_index = (sum_comb_row + sum_comb_col) / 2\n","\n","    return (sum_comb_c - expected_index) / (max_index - expected_index)\n","\n","external_score = adjusted_rand_index_numpy(df['Fruit'].values, labels)\n","print(f\"External Metric (Adjusted Rand Index): {external_score:.4f}\")"],"metadata":{"id":"c1Lb92qqRRyO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767518045545,"user_tz":-180,"elapsed":11,"user":{"displayName":"Efe Feyzi Mantaroğlu","userId":"06606282886702319342"}},"outputId":"11e7609b-864a-493f-df35-a19c04660688"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","CONTINGENCY TABLE (Rows: True Label | Cols: Cluster ID)\n","============================================================\n","True Label           C0      C1      C2      C3      C4\n","-------------------------------------------------------\n","apple               189     114     191      63      65\n","banana              193     139     195      63      66\n","orange              173     116     180      58      81\n","tangerine           192     137     221      61      57\n","tomato              184     114     203      62      65\n","============================================================\n","\n","External Metric (Adjusted Rand Index): -0.0002\n"]}]},{"cell_type":"markdown","source":["### Evaluation of the External Metric\n","The results indicate that our clustering  has failed to find any meaningful patterns related to the fruit types. An Adjusted Rand Index (ARI) of -0.0002 is nearly zero, meaning that the clustering fails, and the reasons are similar to internal metrics."],"metadata":{"id":"wygB_1xDiOMy"}},{"cell_type":"markdown","source":["#### Outlier Detection Method\n","For every individual data point, the code calculates the Euclidean distance ($L_2$ norm) between that point and the center (centroid) of the cluster it was assigned to.\n"," Threshold Mechanism: We uses a percentile-based threshold. By setting threshold_percentile=95,we define an outlier as any point whose distance to its centroid is in the top 5% of all distances in the dataset."],"metadata":{"id":"S8iWZObNiTTb"}},{"cell_type":"code","source":["def detect_outliers_by_cluster(X, centroids, labels, threshold_percentile=95):\n","    #Outliers are the  points that are furthest from their assigned centroids.\n","    distances = []\n","\n","    for i in range(len(X)):\n","        centroid = centroids[labels[i]]\n","        dist = np.linalg.norm(X[i] - centroid)\n","        distances.append(dist)\n","\n","    distances = np.array(distances)\n","\n","    #distance threshold for the top X% furthest points\n","    threshold = np.percentile(distances, threshold_percentile)\n","\n","    outlier_booleans = distances > threshold\n","\n","    return outlier_booleans, distances\n","\n","outlier_booleans, dists = detect_outliers_by_cluster(X_clustering, centroids, labels)\n","\n","# the indices of the top outliers\n","outlier_indices = np.where(outlier_booleans)[0]\n","print(f\"Total Outliers detected: {len(outlier_indices)}\")"],"metadata":{"id":"DoNn1M0DbKlW","executionInfo":{"status":"error","timestamp":1767728089534,"user_tz":-180,"elapsed":39,"user":{"displayName":"Cengiz Sarı","userId":"07073946851309561314"}},"colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"6a80f35e-cd16-4aa2-b841-bf2b8f4378df"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X_clustering' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3892602956.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutlier_booleans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0moutlier_booleans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_outliers_by_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_clustering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# the indices of the top outliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_clustering' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qQCOrWJVbNVn"},"execution_count":null,"outputs":[]}]}